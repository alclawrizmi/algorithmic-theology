# Spec — Complexity classes → belief revision

- Date (UTC): 2026-02-27
- Pair key: `complexity_classes::belief revision`
- Selection rationale: chosen uniformly at random among **least-covered** CS concepts (min coverage count = 0).

## Target proposition (P)
In realistic epistemic settings, **belief revision is computationally resource-bounded**; therefore, two agents with the same priors and evidence can rationally diverge because the *ideal* update is intractable (or practically unreachable).

## CS concept
**Complexity classes** as a lens on what kinds of belief updates are feasible under time/memory constraints.

We operationalize “ideal” belief revision as exact Bayesian updating over a hypothesis space of size **K** (O(K) per evidence item). We operationalize a resource-bounded updater as a fixed-budget method that can only track **M ≪ K** hypotheses at once (a crude proxy for “polynomial-time/space constraints” relative to the effective problem size).

## Candidates (E)
We treat these as competing models for how belief revision behaves.

- **E1 (Ideal exact updater):** exact Bayes over all K hypotheses each step.
- **E2 (Bounded particle updater):** maintains only M hypotheses (“particles”); resamples/proposes locally.
- **E3 (Greedy challenger updater):** maintains top‑M plus a small set of random challengers each step.

## Invariants / axioms used for pruning
- Probabilities remain normalized (posterior is a distribution).
- Evidence is generated by a fixed (but unknown-to-agent) true hypothesis.
- Updates respect Bayes’ rule *within the represented subset* (bounded methods are “locally Bayesian”).

## Operationalization
Data generation:
- Choose a true hypothesis h* ∈ {0..K-1} uniformly.
- Each hypothesis h has a categorical distribution over symbols s ∈ {0..S-1}.
- At each timestep t, emit evidence symbol e_t ~ P(s | h*).

Updaters:
- Exact: updates all K posteriors.
- Particle: tracks M hypotheses; uses importance weights on evidence, then multinomial resampling; proposes new hypotheses by random jumps with small probability.
- Greedy challenger: updates only its maintained set each step; injects random challengers to allow recovery from early pruning.

## Metrics
Across many trials:
- **Accuracy:** argmax posterior equals h* (0/1) at final timestep.
- **True posterior mass:** P(h* | e_1..e_T).
- **Regret vs exact:** difference in true posterior mass (exact − bounded).
- **Instability:** number of argmax switches over time.
- **Divergence:** average KL(exact || bounded_full) where bounded_full is bounded posterior embedded into K with epsilon smoothing.

## Decision rule
Support for P if, as K grows with fixed budget M:
- bounded methods show increasing regret/divergence and/or instability relative to exact,
- and the gaps persist even with identical priors/evidence streams.

If bounded methods track exact well for large K under small M, that disconfirms the “complexity matters” framing (for this toy model).

## Limitations (pre-registered)
- Hypothesis spaces here are finite and enumerable; real belief revision often involves model misspecification and unbounded hypothesis languages.
- Complexity classes are used metaphorically via budget limits, not formal reductions.
